{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":16295,"databundleVersionId":1099992,"sourceType":"competition"},{"sourceId":1043774,"sourceType":"datasetVersion","datasetId":576560},{"sourceId":1043940,"sourceType":"datasetVersion","datasetId":576634}],"dockerImageVersionId":29862,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"\nLOAD DATA\n\"\"\"\n\nimport numpy as np \nimport pandas as pd \nimport json\n\n\ntrain_df = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/train.csv')\ntest_df = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv')\nsub_df = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/sample_submission.csv')\n\ntrain = np.array(train_df)\ntest = np.array(test_df)\n\n!mkdir -p data\n\n\"\"\"\nSETTINGS\n\"\"\"\n\nuse_cuda = True # whether to use GPU or not","metadata":{"execution":{"iopub.status.busy":"2023-10-31T03:56:54.595573Z","iopub.execute_input":"2023-10-31T03:56:54.595979Z","iopub.status.idle":"2023-10-31T03:56:55.689243Z","shell.execute_reply.started":"2023-10-31T03:56:54.595925Z","shell.execute_reply":"2023-10-31T03:56:55.687816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T03:56:58.560727Z","iopub.execute_input":"2023-10-31T03:56:58.561282Z","iopub.status.idle":"2023-10-31T03:56:58.582319Z","shell.execute_reply.started":"2023-10-31T03:56:58.561204Z","shell.execute_reply":"2023-10-31T03:56:58.581416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\n\"\"\"\nPrepare training data in QA-compatible format\n\"\"\"\n\n# Adpated from https://www.kaggle.com/cheongwoongkang/roberta-baseline-starter-simple-postprocessing\ndef find_all(input_str, search_str):\n    l1 = []\n    length = len(input_str)\n    index = 0\n    while index < length:\n        i = input_str.find(search_str, index)\n        if i == -1:\n            return l1\n        l1.append(i)\n        index = i + 1\n    return l1\n\ndef do_qa_train(train):\n\n    output = []\n    for line in train:\n        context = line[1]\n\n        qas = []\n        question = line[-1]\n        qid = line[0]\n        answers = []\n        answer = line[2]\n        if type(answer) != str or type(context) != str or type(question) != str:\n            print(context, type(context))\n            print(answer, type(answer))\n            print(question, type(question))\n            continue\n        answer_starts = find_all(context, answer)\n        for answer_start in answer_starts:\n            answers.append({'answer_start': answer_start, 'text': answer.lower()})\n            break\n        qas.append({'question': question, 'id': qid, 'is_impossible': False, 'answers': answers})\n\n        output.append({'context': context.lower(), 'qas': qas})\n        \n    return output\n\nqa_train = do_qa_train(train)\n\nwith open('data/train.json', 'w') as outfile:\n    json.dump(qa_train, outfile)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-31T03:56:59.464901Z","iopub.execute_input":"2023-10-31T03:56:59.465282Z","iopub.status.idle":"2023-10-31T03:57:00.951882Z","shell.execute_reply.started":"2023-10-31T03:56:59.465237Z","shell.execute_reply":"2023-10-31T03:57:00.950799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\n\"\"\"\nPrepare testing data in QA-compatible format\n\"\"\"\n\ndef do_qa_test(test):\n    output = []\n    for line in test:\n        context = line[1]\n        qas = []\n        question = line[-1]\n        qid = line[0]\n        if type(context) != str or type(question) != str:\n            print(context, type(context))\n            print(answer, type(answer))\n            print(question, type(question))\n            continue\n        answers = []\n        answers.append({'answer_start': 1000000, 'text': '__None__'})\n        qas.append({'question': question, 'id': qid, 'is_impossible': False, 'answers': answers})\n        output.append({'context': context.lower(), 'qas': qas})\n    return output\n\nqa_test = do_qa_test(test)\n\nwith open('data/test.json', 'w') as outfile:\n    json.dump(qa_test, outfile)","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2023-10-31T03:57:02.376951Z","iopub.execute_input":"2023-10-31T03:57:02.377345Z","iopub.status.idle":"2023-10-31T03:57:02.539899Z","shell.execute_reply.started":"2023-10-31T03:57:02.377301Z","shell.execute_reply":"2023-10-31T03:57:02.538655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Install [simple-transformers](https://github.com/ThilinaRajapakse/simpletransformers), a tool to train and test transformers model easily.","metadata":{}},{"cell_type":"code","source":"#Install simple-transformers, a tool to train and test transformers model easily.\n!pip install '/kaggle/input/simple-transformers-pypi/seqeval-0.0.12-py3-none-any.whl' -q\n!pip install '/kaggle/input/simple-transformers-pypi/simpletransformers-0.22.1-py3-none-any.whl' -q","metadata":{"execution":{"iopub.status.busy":"2023-10-30T19:11:02.915821Z","iopub.execute_input":"2023-10-30T19:11:02.916250Z","iopub.status.idle":"2023-10-30T19:11:59.412142Z","shell.execute_reply.started":"2023-10-30T19:11:02.916191Z","shell.execute_reply":"2023-10-30T19:11:59.411131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train model\n\nTrain the `distilbert-base-uncased-distilled-squad` model","metadata":{}},{"cell_type":"code","source":"%%time\n\n\nfrom simpletransformers.question_answering import QuestionAnsweringModel\n\nMODEL_PATH = '/kaggle/input/transformers-pretrained-distilbert/distilbert-base-uncased-distilled-squad/'\n\n# Create the QuestionAnsweringModel\nmodel = QuestionAnsweringModel('distilbert', \n                               MODEL_PATH, \n                               args={'reprocess_input_data': True,\n                                     'overwrite_output_dir': True,\n                                     'learning_rate': 5e-5,\n                                     'num_train_epochs': 3,\n                                     'max_seq_length': 192,\n                                     'doc_stride': 64,\n                                     'fp16': False,\n                                    },\n                              use_cuda=use_cuda)\n\nmodel.train_model('data/train.json')","metadata":{"execution":{"iopub.status.busy":"2023-10-31T03:57:08.418927Z","iopub.execute_input":"2023-10-31T03:57:08.419365Z","iopub.status.idle":"2023-10-31T04:14:51.296941Z","shell.execute_reply.started":"2023-10-31T03:57:08.419305Z","shell.execute_reply":"2023-10-31T04:14:51.295741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Submission","metadata":{}},{"cell_type":"code","source":"%%time\n\npredictions = model.predict(qa_test)\npredictions_df = pd.DataFrame.from_dict(predictions)\n\nsub_df['selected_text'] = predictions_df['answer']\nsub_df\n#sub_df.to_csv('submission.csv', index=False)\n\n#print(\"File submitted successfully.\")","metadata":{"execution":{"iopub.status.busy":"2023-10-30T19:32:53.143518Z","iopub.execute_input":"2023-10-30T19:32:53.143969Z","iopub.status.idle":"2023-10-30T19:33:29.257483Z","shell.execute_reply.started":"2023-10-30T19:32:53.143900Z","shell.execute_reply":"2023-10-30T19:33:29.256641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"similarities = []\n\nfor i in range(len(qa_test)):\n    predicted_text = predictions_df['answer'][i]\n    original_text = qa_test[i]['context']  # Use the original text from the test data\n    predicted_words = set(predicted_text.split())\n    original_words = set(original_text.split())\n    similarity = len(predicted_words.intersection(original_words)) / len(predicted_words.union(original_words))\n    similarities.append(similarity)\n\n# Calculate the average similarity score\naverage_similarity_score = sum(similarities) / len(similarities)\n\nprint(\"Average Similarity Score:\", average_similarity_score)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-10-30T19:41:03.765191Z","iopub.execute_input":"2023-10-30T19:41:03.765673Z","iopub.status.idle":"2023-10-30T19:41:03.871193Z","shell.execute_reply.started":"2023-10-30T19:41:03.765607Z","shell.execute_reply":"2023-10-30T19:41:03.870243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"average_similarity_score","metadata":{"execution":{"iopub.status.busy":"2023-10-31T03:56:47.708408Z","iopub.execute_input":"2023-10-31T03:56:47.708831Z","iopub.status.idle":"2023-10-31T03:56:48.119034Z","shell.execute_reply.started":"2023-10-31T03:56:47.708782Z","shell.execute_reply":"2023-10-31T03:56:48.117354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nimport nltk\nfrom nltk.corpus import stopwords\n\nfrom tqdm import tqdm\nimport os\nimport nltk\nimport spacy\nimport random\nfrom spacy.util import compounding\nfrom spacy.util import minibatch\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n","metadata":{"execution":{"iopub.status.busy":"2023-10-30T19:51:10.695835Z","iopub.execute_input":"2023-10-30T19:51:10.696286Z","iopub.status.idle":"2023-10-30T19:51:11.169703Z","shell.execute_reply.started":"2023-10-30T19:51:10.696219Z","shell.execute_reply":"2023-10-30T19:51:11.168936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/train.csv')\ndf_test = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv')\ndf_submission = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-10-30T19:46:21.066987Z","iopub.execute_input":"2023-10-30T19:46:21.067387Z","iopub.status.idle":"2023-10-30T19:46:21.156151Z","shell.execute_reply.started":"2023-10-30T19:46:21.067341Z","shell.execute_reply":"2023-10-30T19:46:21.155356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['Num_words_text'] = df_train['text'].apply(lambda x:len(str(x).split())) #Number Of words in main Text in train set\n","metadata":{"execution":{"iopub.status.busy":"2023-10-30T19:46:28.363295Z","iopub.execute_input":"2023-10-30T19:46:28.363674Z","iopub.status.idle":"2023-10-30T19:46:28.421069Z","shell.execute_reply.started":"2023-10-30T19:46:28.363630Z","shell.execute_reply":"2023-10-30T19:46:28.420045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = df_train[df_train['Num_words_text']>=3]\ndf_train","metadata":{"execution":{"iopub.status.busy":"2023-10-30T19:46:45.799857Z","iopub.execute_input":"2023-10-30T19:46:45.800231Z","iopub.status.idle":"2023-10-30T19:46:45.823153Z","shell.execute_reply.started":"2023-10-30T19:46:45.800186Z","shell.execute_reply":"2023-10-30T19:46:45.822173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_model(output_dir, nlp, new_model_name):\n    ''' This Function Saves model to \n    given output directory'''\n    \n    output_dir = f'../working/{output_dir}'\n    if output_dir is not None:        \n        if not os.path.exists(output_dir):\n            os.makedirs(output_dir)\n        nlp.meta[\"name\"] = new_model_name\n        nlp.to_disk(output_dir)\n        print(\"Saved model to\", output_dir)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-30T19:47:05.273678Z","iopub.execute_input":"2023-10-30T19:47:05.274058Z","iopub.status.idle":"2023-10-30T19:47:05.280797Z","shell.execute_reply.started":"2023-10-30T19:47:05.274014Z","shell.execute_reply":"2023-10-30T19:47:05.279791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pass model = nlp if you want to train on top of existing model \n#Adapted from: https://spacy.io/usage/training#ner and \n#https://www.kaggle.com/code/tanulsingh077/twitter-sentiment-extaction-analysis-eda-and-model#Modelling\n\ndef train(train_data, output_dir, n_iter=20, model=None):\n    \"\"\"Load the model, set up the pipeline and train the entity recognizer.\"\"\"\n    \"\"\n    if model is not None:\n        nlp = spacy.load(output_dir)  # load existing spaCy model\n        print(\"Loaded model '%s'\" % model)\n    else:\n        nlp = spacy.blank(\"en\")  # create blank Language class\n        print(\"Created blank 'en' model\")\n    \n    # create the built-in pipeline components and add them to the pipeline\n    # nlp.create_pipe works for built-ins that are registered with spaCy\n    if \"ner\" not in nlp.pipe_names:\n        ner = nlp.create_pipe(\"ner\")\n        nlp.add_pipe(ner, last=True)\n    # otherwise, get it so we can add labels\n    else:\n        ner = nlp.get_pipe(\"ner\")\n    \n    # add labels\n    for _, annotations in train_data:\n        for ent in annotations.get(\"entities\"):\n            ner.add_label(ent[2])\n\n    # get names of other pipes to disable them during training\n    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n    with nlp.disable_pipes(*other_pipes):  # only train NER\n        # sizes = compounding(1.0, 4.0, 1.001)\n        # batch up the examples using spaCy's minibatch\n        if model is None:\n            nlp.begin_training()\n        else:\n            nlp.resume_training()\n\n\n        for itn in tqdm(range(n_iter)):\n            random.shuffle(train_data)\n            batches = minibatch(train_data, size=compounding(4.0, 500.0, 1.001))    \n            losses = {}\n            for batch in batches:\n                texts, annotations = zip(*batch)\n                nlp.update(texts,  # batch of texts\n                            annotations,  # batch of annotations\n                            drop=0.5,   # dropout - make it harder to memorise data\n                            losses=losses, \n                            )\n            print(\"Losses\", losses)\n    save_model(output_dir, nlp, 'st_ner')\n","metadata":{"execution":{"iopub.status.busy":"2023-10-30T19:48:13.675329Z","iopub.execute_input":"2023-10-30T19:48:13.675723Z","iopub.status.idle":"2023-10-30T19:48:13.693630Z","shell.execute_reply.started":"2023-10-30T19:48:13.675678Z","shell.execute_reply":"2023-10-30T19:48:13.692603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model_out_path(sentiment):\n    '''\n    Returns Model output path\n    '''\n    model_out_path = None\n    if sentiment == 'positive':\n        model_out_path = 'models/model_pos'\n    elif sentiment == 'negative':\n        model_out_path = 'models/model_neg'\n    return model_out_path","metadata":{"execution":{"iopub.status.busy":"2023-10-30T19:59:35.102993Z","iopub.execute_input":"2023-10-30T19:59:35.103371Z","iopub.status.idle":"2023-10-30T19:59:35.108611Z","shell.execute_reply.started":"2023-10-30T19:59:35.103326Z","shell.execute_reply":"2023-10-30T19:59:35.107673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_training_data(sentiment):\n    '''\n    Returns Trainong data in the format needed to train spacy NER\n    '''\n    train_data = []\n    for index, row in df_train.iterrows():\n        if row.sentiment == sentiment:\n            selected_text = row.selected_text\n            text = row.text\n            start = text.find(selected_text)\n            end = start + len(selected_text)\n            train_data.append((text, {\"entities\": [[start, end, 'selected_text']]}))\n    return train_data","metadata":{"execution":{"iopub.status.busy":"2023-10-30T19:59:37.506245Z","iopub.execute_input":"2023-10-30T19:59:37.506653Z","iopub.status.idle":"2023-10-30T19:59:37.513179Z","shell.execute_reply.started":"2023-10-30T19:59:37.506594Z","shell.execute_reply":"2023-10-30T19:59:37.512313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentiment = 'positive'\n\ntrain_data = get_training_data(sentiment)\nmodel_path = get_model_out_path(sentiment)\n# For DEmo Purposes I have taken 3 iterations you can train the model as you want\ntrain(train_data, model_path, n_iter=3, model=None)","metadata":{"execution":{"iopub.status.busy":"2023-10-30T19:51:16.587695Z","iopub.execute_input":"2023-10-30T19:51:16.588064Z","iopub.status.idle":"2023-10-30T19:53:20.301726Z","shell.execute_reply.started":"2023-10-30T19:51:16.588019Z","shell.execute_reply":"2023-10-30T19:53:20.300558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentiment = 'negative'\n\ntrain_data = get_training_data(sentiment)\nmodel_path = get_model_out_path(sentiment)\n\ntrain(train_data, model_path, n_iter=3, model=None)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-30T19:54:38.114060Z","iopub.execute_input":"2023-10-30T19:54:38.114483Z","iopub.status.idle":"2023-10-30T19:56:32.034678Z","shell.execute_reply.started":"2023-10-30T19:54:38.114432Z","shell.execute_reply":"2023-10-30T19:56:32.033470Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_entities(text, model):\n    doc = model(text)\n    ent_array = []\n    for ent in doc.ents:\n        start = text.find(ent.text)\n        end = start + len(ent.text)\n        new_int = [start, end, ent.label_]\n        if new_int not in ent_array:\n            ent_array.append([start, end, ent.label_])\n    selected_text = text[ent_array[0][0]: ent_array[0][1]] if len(ent_array) > 0 else text\n    return selected_text","metadata":{"execution":{"iopub.status.busy":"2023-10-30T19:59:43.124012Z","iopub.execute_input":"2023-10-30T19:59:43.124387Z","iopub.status.idle":"2023-10-30T19:59:43.131817Z","shell.execute_reply.started":"2023-10-30T19:59:43.124343Z","shell.execute_reply":"2023-10-30T19:59:43.130769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"selected_texts = []\nMODELS_BASE_PATH = '../input/tse-spacy-model/models/'\n\nif MODELS_BASE_PATH is not None:\n    print(\"Loading Models  from \", MODELS_BASE_PATH)\n    model_pos = spacy.load(MODELS_BASE_PATH + 'model_pos')\n    model_neg = spacy.load(MODELS_BASE_PATH + 'model_neg')\n        \n    for index, row in df_test.iterrows():\n        text = row.text\n        output_str = \"\"\n        if row.sentiment == 'neutral' or len(text.split()) <= 2:\n            selected_texts.append(text)\n        elif row.sentiment == 'positive':\n            selected_texts.append(predict_entities(text, model_pos))\n        else:\n            selected_texts.append(predict_entities(text, model_neg))\n        \ndf_test['selected_text'] = selected_texts","metadata":{"execution":{"iopub.status.busy":"2023-10-30T19:59:48.474221Z","iopub.execute_input":"2023-10-30T19:59:48.474628Z","iopub.status.idle":"2023-10-30T19:59:48.513992Z","shell.execute_reply.started":"2023-10-30T19:59:48.474579Z","shell.execute_reply":"2023-10-30T19:59:48.512593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submission['selected_text'] = df_test['selected_text']\ndf_submission.to_csv(\"submission.csv\", index=False)\ndisplay(df_submission.head(10))","metadata":{"execution":{"iopub.status.busy":"2023-10-30T19:58:40.158060Z","iopub.execute_input":"2023-10-30T19:58:40.158450Z","iopub.status.idle":"2023-10-30T19:58:40.325110Z","shell.execute_reply.started":"2023-10-30T19:58:40.158392Z","shell.execute_reply":"2023-10-30T19:58:40.323483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd, numpy as np\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom sklearn.model_selection import StratifiedKFold\nfrom transformers import *\nimport tokenizers\nprint('TF version',tf.__version__)\n\nMAX_LEN = 96\nPATH = '../input/tf-roberta/'\ntokenizer = tokenizers.ByteLevelBPETokenizer(\n    vocab_file=PATH+'vocab-roberta-base.json', \n    merges_file=PATH+'merges-roberta-base.txt', \n    lowercase=True,\n    add_prefix_space=True\n)\nsentiment_id = {'positive': 1313, 'negative': 2430, 'neutral': 7974}\ntrain = pd.read_csv('../input/tweet-sentiment-extraction/train.csv').fillna('')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-22T19:50:13.526681Z","iopub.execute_input":"2023-11-22T19:50:13.527042Z","iopub.status.idle":"2023-11-22T19:50:22.328938Z","shell.execute_reply.started":"2023-11-22T19:50:13.526999Z","shell.execute_reply":"2023-11-22T19:50:22.327359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}